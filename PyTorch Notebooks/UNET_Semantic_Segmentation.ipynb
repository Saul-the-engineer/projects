{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UNET_Segmentation.ipynb","provenance":[],"authorship_tag":"ABX9TyOBqtBnsOWqNK4QsG+7Nhsf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"1TkQ6fmNX3nl"},"source":["import tensorflow as tf\n","import os\n","import random\n","import numpy as np\n","from tqdm import tqdm \n","from skimage.io import imread, imshow\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CxQ4EScLcmmR"},"source":["# Constant\n","seed = 42\n","np.random.seed = seed\n","IMG_WIDTH = 128\n","IMG_HEIGHT = 128\n","IMG_CHANNELS = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lfaQyGmyYPM9"},"source":["TRAIN_PATH = 'stage1_train/'\n","TEST_PATH = 'stage1_test/'\n","\n","# Data Prep\n","# Gets Folder Names of Folders within Data\n","train_ids = next(os.walk(TRAIN_PATH))[1] #Creates touple of path and subfolder. Select subfolder name\n","test_ids = next(os.walk(TEST_PATH))[1]\n","\n","# Create list of zeros same size as id list\n","X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n","Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n","\n","print('Resizing training images and masks')\n","for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n","    path = TRAIN_PATH + id_\n","    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n","    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n","    X_train[n] = img  #Fill empty X_train with values from img\n","    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n","    for mask_file in next(os.walk(path + '/masks/'))[2]:\n","        mask_ = imread(path + '/masks/' + mask_file)\n","        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)\n","        mask = np.maximum(mask, mask_)  \n","            \n","    Y_train[n] = mask   \n","\n","# test images\n","X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n","sizes_test = []\n","print('Resizing test images') \n","for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n","    path = TEST_PATH + id_\n","    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n","    sizes_test.append([img.shape[0], img.shape[1]])\n","    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n","    X_test[n] = img\n","print('Done')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mr8yTHikYU0J"},"source":["#Plot random image\n","image_x = random.randint(0, len(train_ids))\n","imshow(X_train[image_x])\n","plt.show()\n","imshow(np.squeeze(Y_train[image_x]))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F3DGjmevStQz"},"source":["#Build the model\n","inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n","s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n","\n","#Contraction path\n","c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n","c1 = tf.keras.layers.Dropout(0.1)(c1)\n","c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n","p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n","\n","c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n","c2 = tf.keras.layers.Dropout(0.1)(c2)\n","c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n","p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n"," \n","c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n","c3 = tf.keras.layers.Dropout(0.2)(c3)\n","c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n","p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n"," \n","c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n","c4 = tf.keras.layers.Dropout(0.2)(c4)\n","c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n","p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)\n"," \n","c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n","c5 = tf.keras.layers.Dropout(0.3)(c5)\n","c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n","\n","#Expansive path \n","u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n","u6 = tf.keras.layers.concatenate([u6, c4])\n","c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n","c6 = tf.keras.layers.Dropout(0.2)(c6)\n","c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n"," \n","u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n","u7 = tf.keras.layers.concatenate([u7, c3])\n","c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n","c7 = tf.keras.layers.Dropout(0.2)(c7)\n","c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n"," \n","u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n","u8 = tf.keras.layers.concatenate([u8, c2])\n","c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n","c8 = tf.keras.layers.Dropout(0.1)(c8)\n","c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n"," \n","u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n","u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n","c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n","c9 = tf.keras.layers.Dropout(0.1)(c9)\n","c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n"," \n","outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n"," \n","model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oxpf-p_dXq0s"},"source":["# Model Run\n","checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_nuclei.h5', verbose=1, save_best_only=True)\n","\n","callbacks = [tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n","              tf.keras.callbacks.TensorBoard(log_dir='logs')]\n","\n","results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=25, callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MlWCfHJticn8"},"source":["idx = random.randint(0, len(X_train))\n","\n","preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n","preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n","preds_test = model.predict(X_test, verbose=1)\n","\n","# Convert thresholds to binary\n","preds_train_t = (preds_train > 0.5).astype(np.uint8)\n","preds_val_t = (preds_val > 0.5).astype(np.uint8)\n","preds_test_t = (preds_test > 0.5).astype(np.uint8)\n","\n","# Perform a sanity check on some random training samples\n","ix = random.randint(0, len(preds_train_t))\n","imshow(X_train[ix])\n","plt.show()\n","imshow(np.squeeze(Y_train[ix]))\n","plt.show()\n","imshow(np.squeeze(preds_train_t[ix]))\n","plt.show()\n","\n","# Perform a sanity check on some random validation samples\n","ix = random.randint(0, len(preds_val_t))\n","imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n","plt.show()\n","imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n","plt.show()\n","imshow(np.squeeze(preds_val_t[ix]))\n","plt.show()"],"execution_count":null,"outputs":[]}]}