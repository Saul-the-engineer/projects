{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff9993addf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating random input data\n",
    "num_samples = 1000\n",
    "\n",
    "# Generating input_A (5 features)\n",
    "x_a = np.random.rand(num_samples, 5).astype(np.float32)\n",
    "\n",
    "# Generating input_B (6 features)\n",
    "x_b = np.random.rand(num_samples, 6).astype(np.float32)\n",
    "\n",
    "# Generating output (target variable for main output and auxiliary output)\n",
    "# Let's assume the output for main and auxiliary tasks are correlated to some extent\n",
    "# Generating main output (target for main task)\n",
    "y_main = 3 * x_a[:, 0] + 2 * x_a[:, 1] - 5 * x_a[:, 2] + np.random.randn(num_samples)\n",
    "\n",
    "# Generating auxiliary output (target for auxiliary task)\n",
    "y_aux = 0.5 * x_b[:, 0] + 1.5 * x_b[:, 1] + np.random.randn(num_samples)\n",
    "\n",
    "# Splitting data into train and validation sets\n",
    "X_train_A, X_valid_A, X_train_B, X_valid_B, y_train_main, y_valid_main, y_train_aux, y_valid_aux = train_test_split(\n",
    "    x_a, x_b, y_main, y_aux, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 30)\n",
    "        self.bn1 = nn.BatchNorm1d(30)\n",
    "        self.fc2 = nn.Linear(30, 30)\n",
    "        self.main_output = nn.Linear(35, 1)  # 5 (wide_input) + 30 (hidden2)\n",
    "        self.aux_output = nn.Linear(30, 1)\n",
    "\n",
    "    def forward(self, input_A, input_B):\n",
    "        x = F.relu(self.fc1(input_B))\n",
    "        x = self.bn1(x)\n",
    "        x = (self.fc2(x))\n",
    "        \n",
    "        # Concatenate input_A with hidden2_output\n",
    "        concat = torch.cat((input_A, x), dim=1)\n",
    "        \n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(x)\n",
    "        \n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your data to torch.float32 using clone().detach()\n",
    "X_train_A = X_train_A.clone().detach().float()\n",
    "X_train_B = X_train_B.clone().detach().float()\n",
    "y_train_main = y_train_main.clone().detach().float().view(-1, 1)\n",
    "y_train_aux = y_train_aux.clone().detach().float().view(-1, 1)\n",
    "\n",
    "X_valid_A = X_valid_A.clone().detach().float()\n",
    "X_valid_B = X_valid_B.clone().detach().float()\n",
    "y_valid_main = y_valid_main.clone().detach().float().view(-1, 1)\n",
    "y_valid_aux = y_valid_aux.clone().detach().float().view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Main Loss: Train 4.3268, Valid 3.7887 Aux Loss: Train 1.6637, Valid 1.6789\n",
      "Epoch [2/20] Main Loss: Train 4.2782, Valid 3.7871 Aux Loss: Train 1.6513, Valid 1.6892\n",
      "Epoch [3/20] Main Loss: Train 4.2501, Valid 3.7577 Aux Loss: Train 1.6450, Valid 1.7024\n",
      "Epoch [4/20] Main Loss: Train 4.1867, Valid 3.7392 Aux Loss: Train 1.6270, Valid 1.6786\n",
      "Epoch [5/20] Main Loss: Train 4.1784, Valid 3.7170 Aux Loss: Train 1.6200, Valid 1.6690\n",
      "Epoch [6/20] Main Loss: Train 4.1173, Valid 3.6940 Aux Loss: Train 1.5940, Valid 1.6644\n",
      "Epoch [7/20] Main Loss: Train 4.1198, Valid 3.6716 Aux Loss: Train 1.5852, Valid 1.6438\n",
      "Epoch [8/20] Main Loss: Train 4.0855, Valid 3.6438 Aux Loss: Train 1.5948, Valid 1.6410\n",
      "Epoch [9/20] Main Loss: Train 4.0499, Valid 3.6170 Aux Loss: Train 1.5731, Valid 1.6201\n",
      "Epoch [10/20] Main Loss: Train 4.0190, Valid 3.5941 Aux Loss: Train 1.5632, Valid 1.6270\n",
      "Epoch [11/20] Main Loss: Train 3.9890, Valid 3.5714 Aux Loss: Train 1.5462, Valid 1.6216\n",
      "Epoch [12/20] Main Loss: Train 3.9640, Valid 3.5486 Aux Loss: Train 1.5333, Valid 1.6028\n",
      "Epoch [13/20] Main Loss: Train 3.9385, Valid 3.5313 Aux Loss: Train 1.5089, Valid 1.5950\n",
      "Epoch [14/20] Main Loss: Train 3.9131, Valid 3.5075 Aux Loss: Train 1.5080, Valid 1.5895\n",
      "Epoch [15/20] Main Loss: Train 3.9040, Valid 3.4868 Aux Loss: Train 1.5093, Valid 1.5724\n",
      "Epoch [16/20] Main Loss: Train 3.8723, Valid 3.4706 Aux Loss: Train 1.4898, Valid 1.5587\n",
      "Epoch [17/20] Main Loss: Train 3.8483, Valid 3.4544 Aux Loss: Train 1.4726, Valid 1.5831\n",
      "Epoch [18/20] Main Loss: Train 3.8267, Valid 3.4248 Aux Loss: Train 1.4695, Valid 1.5370\n",
      "Epoch [19/20] Main Loss: Train 3.7982, Valid 3.4042 Aux Loss: Train 1.4560, Valid 1.5253\n",
      "Epoch [20/20] Main Loss: Train 3.7619, Valid 3.3835 Aux Loss: Train 1.4613, Valid 1.5296\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = CustomModel()\n",
    "\n",
    "# Define optimizer and loss functions for each output\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion_main = nn.MSELoss()\n",
    "criterion_aux = nn.MSELoss()\n",
    "\n",
    "# Assuming X_train_A, X_train_B, y_train, X_valid_A, X_valid_B, y_valid are torch tensors\n",
    "train_dataset = TensorDataset(X_train_A, X_train_B, y_train_main, y_train_aux)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "valid_dataset = TensorDataset(X_valid_A, X_valid_B, y_valid_main, y_valid_aux)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_main_loss = 0.0\n",
    "    epoch_aux_loss = 0.0\n",
    "\n",
    "    for input_A, input_B, target_main, target_aux in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output_main, output_aux = model(input_A, input_B)\n",
    "        loss_main = criterion_main(output_main, target_main)\n",
    "        loss_aux = criterion_aux(output_aux, target_aux)\n",
    "        total_loss = 0.9 * loss_main + 0.1 * loss_aux  # Weighted combination of losses\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_main_loss += loss_main.item() * input_A.size(0)\n",
    "        epoch_aux_loss += loss_aux.item() * input_A.size(0)\n",
    "\n",
    "    epoch_main_loss /= len(train_loader.dataset)\n",
    "    epoch_aux_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_main_loss = 0.0\n",
    "        valid_aux_loss = 0.0\n",
    "        for input_A, input_B, target_main, target_aux in valid_loader:\n",
    "            output_main, output_aux = model(input_A, input_B)\n",
    "            valid_main_loss += criterion_main(output_main, target_main).item() * input_A.size(0)\n",
    "            valid_aux_loss += criterion_aux(output_aux, target_aux).item() * input_A.size(0)\n",
    "\n",
    "        valid_main_loss /= len(valid_loader.dataset)\n",
    "        valid_aux_loss /= len(valid_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
    "          f\"Main Loss: Train {epoch_main_loss:.4f}, Valid {valid_main_loss:.4f} \"\n",
    "          f\"Aux Loss: Train {epoch_aux_loss:.4f}, Valid {valid_aux_loss:.4f}\")\n",
    "\n",
    "# Use the trained model for predictions, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
