{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level Language Model Using GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this excercise is to build a character level language model based on the GRU model with pytorch. The model follows the char-rnn-karpathy model. The model is trained on the text of the book \"The lord of the rings\". The model is trained on the GPU.\n",
    "\n",
    "The overall concept is that individual characters are embedded into a vector space size [batch, seq_length, hidden_space]. The embedding is then fed into a GRU cell. The output of the GRU cell is then fed into a fully connected layer. The output of the fully connected layer is then fed into a softmax layer. The softmax layer then predicts the next character based on argmax.\n",
    "\n",
    "The model is trained on a sequence of characters. The sequence is then shifted by one character and the model is trained again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "from typing import Tuple, List, Dict\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text, label):\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.text[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chunk(text: str, chunk_len: int = 200):\n",
    "  start_index = random.randint(0, len(text) - chunk_len)\n",
    "  end_index = start_index + chunk_len + 1\n",
    "  return text[start_index:end_index]\n",
    "\n",
    "# Turn string into list of longs\n",
    "def tokenizer(string: str, vocab: List[str]):\n",
    "  tensor = torch.zeros(len(string)).long()\n",
    "  for c in range(len(string)):\n",
    "      tensor[c] = vocab.index(string[c])\n",
    "  return tensor\n",
    "\n",
    "def detokenizer(tensor: torch.Tensor, vocab: List[str]):\n",
    "  string = \"\"\n",
    "  for t in tensor:\n",
    "    string += vocab[t]\n",
    "  return string\n",
    "\n",
    "def random_training_set(text: str, vocab: List[str], chunk_len: int = 200): \n",
    "  chunk = random_chunk(text, chunk_len)\n",
    "  input_seq = tokenizer(chunk[:-1], vocab)\n",
    "  target = tokenizer(chunk[1:], vocab)\n",
    "  return input_seq, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regex to remove all non-ascii and non-printable characters\n",
    "text_raw = unidecode(open('data/rnn_dataset/text_files/lotr.txt').read())\n",
    "vocab = list(string.printable)\n",
    "n_characters = len(vocab)\n",
    "chunk_len = 500\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw, y_raw = random_training_set(text_raw, vocab, chunk_len=chunk_len)\n",
    "data_train = TextDataset(x_raw, y_raw)\n",
    "dataloader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "Random sample input: tensor([55])\n",
      "torch.Size([1])\n",
      "Random sample target: tensor([10])\n"
     ]
    }
   ],
   "source": [
    "sample_x, sample_y = next(iter(dataloader_train))\n",
    "print(sample_x.shape)\n",
    "print(f\"Random sample input: {sample_x}\")\n",
    "print(sample_y.shape)\n",
    "print(f\"Random sample target: {sample_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample input: T\n",
      "Random sample target: a\n"
     ]
    }
   ],
   "source": [
    "sample_x1 = detokenizer(sample_x, vocab)\n",
    "print(f\"Random sample input: {sample_x1}\")\n",
    "sample_y1 = detokenizer(sample_y, vocab)\n",
    "print(f\"Random sample target: {sample_y1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self, input_size:int, output_size:int, hidden_size:int, n_layers:int = 1):\n",
    "    super(RNN, self).__init__()\n",
    "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "    self.hidden_size = hidden_size\n",
    "    self.gru = nn.GRU(hidden_size, hidden_size, num_layers = n_layers)\n",
    "    self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, input, hidden):\n",
    "    output = self.embedding(input).view(1, 1, -1)\n",
    "    output, hidden = self.gru(output, hidden) # output shape: (1, 1, hidden_size)\n",
    "    output = self.out(output[0])\n",
    "    return output, hidden\n",
    "\n",
    "  def init_hidden(self, batch_size:int = 1, seq_len:int = 1):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    a = torch.zeros(batch_size, seq_len, self.hidden_size).to(device)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, criterion: nn.Module, optimizer: optim.Optimizer, dataloader: DataLoader):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    hidden = model.init_hidden().cuda()\n",
    "    batch_loss = 0\n",
    "    for x, y in dataloader:\n",
    "      x = x.cuda()\n",
    "      y = y.cuda()\n",
    "      y_hat, hidden = model(x, hidden)\n",
    "      loss = criterion(y_hat, y)\n",
    "      batch_loss += loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return batch_loss.detach().item()/len(dataloader)\n",
    "\n",
    "def predict(model:RNN, vocabulary:List[str], primer:str='A', predict_len:int=100, temperature:float=0.8):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval().to(device)\n",
    "    hidden_state = model.init_hidden().to(device)\n",
    "    primer_tokens = tokenizer(primer, vocabulary).to(device)\n",
    "    prediction = primer\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      for char in range(len(primer)-1):\n",
    "        _, hidden_state = model(primer_tokens[char], hidden_state)\n",
    "      input_seq = primer_tokens[-1]\n",
    "\n",
    "      #pdb.set_trace()\n",
    "      for p in range(predict_len):\n",
    "        output, hidden = model(input_seq, hidden_state)\n",
    "        output = output.to(device)\n",
    "        sampled_character = sample_outputs(output.view(-1), temperature)\n",
    "        char_choice = vocabulary[sampled_character]\n",
    "        input_seq = torch.tensor([vocabulary.index(char_choice)], dtype=torch.long).to(device)\n",
    "        prediction += char_choice\n",
    "    return prediction\n",
    "\n",
    "def sample_outputs(output, temperature):\n",
    "    \"\"\"Takes in a vector of unnormalized probability weights and samples a character from the distribution\"\"\"\n",
    "    return torch.multinomial(torch.exp(output) / temperature, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5000\n",
    "hidden_size = 200\n",
    "n_layers = 1\n",
    "lr = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RNN(n_characters, n_characters, hidden_size, n_layers).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "critierion = nn.CrossEntropyLoss()\n",
    "\n",
    "print_every = 100\n",
    "loop = tqdm(total=n_epochs, position=0)\n",
    "training_loss = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1): \n",
    "  loss_train = train(model, critierion, optimizer, dataloader_train)\n",
    "  training_loss.append(loss_train)\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "      print(predict(model, vocab, primer='Wh', predict_len=100, temperature=0.8), '\\n')\n",
    "\n",
    "  loop.update(1)\n",
    "loop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss\n",
    "index_loss = range(len(training_loss))\n",
    "plt.plot(index_loss, training_loss, label='train loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" We\", \" lo\", \" ra\"]\n",
    "for primer in start_strings:\n",
    "  print(predict(model, vocab, primer=primer, predict_len=100, temperature=0.8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
