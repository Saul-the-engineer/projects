{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### A Tour of Transformer Applications"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text is everywhere around us and being able to understand and act on information we can find in text is a crucial aspect in every company.\n",
        "\n",
        "Start with some basic imports\n",
        "\n",
        "Note: You will also need to install pytorch to run this notebook. Install with <pre>pip install torch torchvision"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:26:02.151Z",
          "iopub.execute_input": "2021-12-07T17:26:02.164Z",
          "iopub.status.idle": "2021-12-07T17:26:02.686Z",
          "shell.execute_reply": "2021-12-07T17:26:02.695Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with some text, some feedback from a customer"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
        "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
        "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:26:06.406Z",
          "iopub.execute_input": "2021-12-07T17:26:06.413Z",
          "iopub.status.idle": "2021-12-07T17:26:06.429Z",
          "shell.execute_reply": "2021-12-07T17:26:06.437Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We probably want to want to understand the feedback and then be able to respond. We may also want to use all the feedback we get from all of our reviews and letters to find general trends or anomalies that we should respond to."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hugging Face [Pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines) are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering. See the Hugging Face pipeline [task summary](https://huggingface.co/docs/transformers/master/task_summary) for examples of use.*\n",
        "\n",
        "*There are pipelines for:*\n",
        "* Audio Classification\n",
        "* Conversations\n",
        "* Feature Extraction\n",
        "* Image Classification\n",
        "* Object Detection\n",
        "* Question Answering\n",
        "* Summarization\n",
        "* Text Classification\n",
        "* Text Generation\n",
        "* Translation\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:26:10.876Z",
          "iopub.execute_input": "2021-12-07T17:26:10.884Z",
          "iopub.status.idle": "2021-12-07T17:26:15.962Z",
          "shell.execute_reply": "2021-12-07T17:26:15.968Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with looking at the feedback and determining if it is positive or negative. This task is called sentiment analysis."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:26:37.139Z",
          "iopub.execute_input": "2021-12-07T17:26:37.148Z",
          "iopub.status.idle": "2021-12-07T17:26:41.436Z",
          "shell.execute_reply": "2021-12-07T17:26:41.448Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = classifier(text)\n",
        "pd.DataFrame.from_records(outputs)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "      label     score\n0  NEGATIVE  0.901546",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NEGATIVE</td>\n      <td>0.901546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:26:51.505Z",
          "iopub.execute_input": "2021-12-07T17:26:51.515Z",
          "iopub.status.idle": "2021-12-07T17:26:51.659Z",
          "shell.execute_reply": "2021-12-07T17:26:51.668Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the feedback looks negative. But what is it about?\n",
        "\n",
        "We need to determine the *named entities* that are in the feedback text. This is called Named Entity Recognition (NER). We can apply NER by creating another pipeline and feeding our text to it."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
        "outputs = ner_tagger(text)\n",
        "pd.DataFrame.from_records(outputs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "  entity_group     score           word  start  end\n0          ORG  0.879010         Amazon      5   11\n1         MISC  0.990859  Optimus Prime     36   49\n2          LOC  0.999755        Germany     90   97\n3         MISC  0.556570           Mega    208  212\n4          PER  0.590256         ##tron    212  216\n5          ORG  0.669692         Decept    253  259\n6         MISC  0.498349        ##icons    259  264\n7         MISC  0.775362       Megatron    350  358\n8         MISC  0.987854  Optimus Prime    367  380\n9          PER  0.812096      Bumblebee    502  511",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>entity_group</th>\n      <th>score</th>\n      <th>word</th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ORG</td>\n      <td>0.879010</td>\n      <td>Amazon</td>\n      <td>5</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MISC</td>\n      <td>0.990859</td>\n      <td>Optimus Prime</td>\n      <td>36</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LOC</td>\n      <td>0.999755</td>\n      <td>Germany</td>\n      <td>90</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MISC</td>\n      <td>0.556570</td>\n      <td>Mega</td>\n      <td>208</td>\n      <td>212</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PER</td>\n      <td>0.590256</td>\n      <td>##tron</td>\n      <td>212</td>\n      <td>216</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ORG</td>\n      <td>0.669692</td>\n      <td>Decept</td>\n      <td>253</td>\n      <td>259</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>MISC</td>\n      <td>0.498349</td>\n      <td>##icons</td>\n      <td>259</td>\n      <td>264</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>MISC</td>\n      <td>0.775362</td>\n      <td>Megatron</td>\n      <td>350</td>\n      <td>358</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>MISC</td>\n      <td>0.987854</td>\n      <td>Optimus Prime</td>\n      <td>367</td>\n      <td>380</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>PER</td>\n      <td>0.812096</td>\n      <td>Bumblebee</td>\n      <td>502</td>\n      <td>511</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:27:23.736Z",
          "iopub.execute_input": "2021-12-07T17:27:23.743Z",
          "iopub.status.idle": "2021-12-07T17:27:30.575Z",
          "shell.execute_reply": "2021-12-07T17:27:30.592Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline detected the entities and assigned a category. The pipeline also used the \"aggregation_strategy\" argument to group words according to the model's predictions. So we got \"Optimus Prime\" assigned as a single entity.\n",
        "\n",
        "This is useful when trying to extact the subject of feedback, especially in a large corpus of feedback. Sometimes, we want answers to more targeted questions. This is where we can use *question answering*. For now, we will use the default extractive question answering which extracts phrases from the text to answer the posed question."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reader = pipeline(\"question-answering\")\n",
        "question = \"What does the customer want?\"\n",
        "outputs = reader(question=question, context=text)\n",
        "pd.DataFrame.from_records([outputs])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "      score  start  end                   answer\n0  0.631292    335  358  an exchange of Megatron",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>start</th>\n      <th>end</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.631292</td>\n      <td>335</td>\n      <td>358</td>\n      <td>an exchange of Megatron</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:28:21.487Z",
          "iopub.execute_input": "2021-12-07T17:28:21.496Z",
          "iopub.status.idle": "2021-12-07T17:28:25.887Z",
          "shell.execute_reply": "2021-12-07T17:28:25.897Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also summarize long texts into shorter texts that have the relevant facts. This is a much more complicated task since we want to produce coherent text as output. There is a lot of current research on this topic. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "outputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\n",
        "print(\"Summary: \", outputs[0]['summary_text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:   Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead.\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:28:52.941Z",
          "iopub.execute_input": "2021-12-07T17:28:52.952Z",
          "iopub.status.idle": "2021-12-07T17:29:02.482Z",
          "shell.execute_reply": "2021-12-07T17:29:02.494Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hugging Face also provides a pipeline task to translate from one language to another.\n",
        "\n",
        "You must also directly specify the model to be used.\n",
        "\n",
        "Go to [the Hugging Face Models](https://huggingface.co/models) page to find the model you want to use."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece\n",
        "#translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
        "print(\"Translation: \", outputs[0]['translation_text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation:  Cher Amazon, la semaine dernière j'ai commandé une figure d'action Optimus Prime de votre boutique en ligne en Allemagne. Malheureusement, quand j'ai ouvert le paquet, j'ai découvert à mon horreur que j'avais été envoyé une figure d'action de Megatron à la place! En tant qu'ennemi à vie des Decepticons, j'espère que vous pouvez comprendre mon dilemme. Pour résoudre le problème, j'exige un échange de Megatron contre la figure d'Optimus Prime que j'ai commandé.\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:29:55.971Z",
          "iopub.execute_input": "2021-12-07T17:29:55.979Z",
          "iopub.status.idle": "2021-12-07T17:30:07.283Z",
          "shell.execute_reply": "2021-12-07T17:30:07.296Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, maybe we want some help generating a response to the customer. We can use the text-generation pipeline. We give the pipeline some initial text and let it generate text that could follow what we have written."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "set_seed(42)\n",
        "generator = pipeline(\"text-generation\")\n",
        "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
        "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
        "outputs = generator(prompt, max_length=200)\n",
        "print(outputs[0]['generated_text'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\n",
            "\n",
            "Customer service response:\n",
            "Dear Bumblebee, I am sorry to hear that your order was mixed up. The order was completely mislabeled, which is very common in our online store, but I can appreciate it because it was my understanding from this site and our customer service of the previous day that your order was not made correct in our mind and that we are in a process of resolving this matter. We can assure you that your order\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2021-12-07T17:32:08.791Z",
          "iopub.execute_input": "2021-12-07T17:32:08.798Z",
          "iopub.status.idle": "2021-12-07T17:32:16.215Z",
          "shell.execute_reply": "2021-12-07T17:32:16.230Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "argv": [
        "/Users/snell/mypython/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "metadata": {
        "debugger": true
      },
      "name": "python3"
    },
    "nteract": {
      "version": "0.28.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}