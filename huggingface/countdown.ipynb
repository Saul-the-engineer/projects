{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Fine-Tuning LLaMA on the Countdown Task with GRPO\n",
    "\n",
    "Welcome to this notebook where we bring together two powerful ideas:\n",
    "\n",
    "- üîÅ **Group Relative Policy Optimization (GRPO)** ‚Äì a novel, efficient reinforcement learning technique for aligning large language models, and  \n",
    "- üî¢ **The Countdown Task** ‚Äì a symbolic reasoning challenge where models must compose equations using basic arithmetic to hit a target value.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ The Countdown Task\n",
    "\n",
    "Given a list of numbers and a target value, the model must generate an equation using **each number exactly once**, applying basic operations:\n",
    "\n",
    "$$\n",
    "\\text{Operations: } +,\\ -,\\ \\times,\\ \\div\n",
    "$$\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```text\n",
    "Numbers: [3, 7, 50], Target: 29  \n",
    "Solution: (50 - 7) + (3) = 46 ‚Üí ‚ùå  \n",
    "         ((50 / (7 + 3)) + 3) = 8 ‚Üí ‚ùå  \n",
    "         (7 * 3) + 8 = 29 ‚Üí ‚úÖ (if 8 was in the list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmalign.model import load_model_and_tokenizer\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "from datasets import DatasetDict, load_dataset, Dataset\n",
    "import random\n",
    "import torch\n",
    "import regex as re\n",
    "from typing import List, Dict, Any, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# Set seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Set deterministic behavior (optional, but useful for debugging)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# HF transformers seed\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"id\": \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        \"quantization\": {\n",
    "            \"enabled\": True,\n",
    "            \"type\": \"4bit\",\n",
    "            \"compute_dtype\": \"bf16\",\n",
    "        },\n",
    "        \"peft_settings\": {\n",
    "            \"enabled\": True,\n",
    "            \"mode\": \"create\",\n",
    "            \"lora_config\": {\n",
    "                \"r\": 16,\n",
    "                \"alpha\": 32,\n",
    "                \"dropout\": 0.05,\n",
    "                \"target_modules\": \"all-linear\",\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    \"tokenizer\": {\"id\": \"meta-llama/Llama-3.1-8B-Instruct\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_batch_to_chatml(batch, system_prompt, user_template, assistant_template):\n",
    "    all_conversations = []\n",
    "    # Use zip for cleaner iteration over columns in the batch\n",
    "    for target, numbers in zip(batch[\"target\"], batch[\"nums\"]):\n",
    "        numbers_str = \", \".join(map(str, numbers))\n",
    "        conversation = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_template.format(numbers=numbers_str, target=target)},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_template},\n",
    "        ]\n",
    "        all_conversations.append(conversation)\n",
    "    # Return a dictionary where the key is the new column name\n",
    "    # and the value is the list of processed items for the batch\n",
    "    return {\"prompt\": all_conversations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant \"\n",
    "    \"first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
    "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
    "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
    ")\n",
    "user_template = (\n",
    "    \"Using the numbers {numbers}, create an equation that equals {target} and provide the solution step by step. \"\n",
    "    \"You can use basic arithmetic operations (+, -, *, /) and parentheses to create the equation. \"\n",
    "    \"Each number can only be used once. If it is not possible to create an equation, please say 'impossible'.\"\n",
    ")\n",
    "assistent_template = \"Let me solve this step by step. <think>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Jiayi-Pan/Countdown-Tasks-3to4\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Jiayi-Pan/Countdown-Tasks-3to4\", split=\"train\")\n",
    "dataset = dataset.select(range(50_000))\n",
    "dataset = dataset.map(\n",
    "    format_batch_to_chatml,  # Use the batched version\n",
    "    batched=True,  # Process in batches (highly recommended)\n",
    "    fn_kwargs={\n",
    "        \"system_prompt\": system_prompt,\n",
    "        \"user_template\": user_template,\n",
    "        \"assistant_template\": assistent_template,  # Pass the variable\n",
    "    },\n",
    ")\n",
    "train_test_split = dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_test_split\n",
    "del train_dataset\n",
    "del test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test getting an output:\n",
    "\n",
    "# sample = dataset[\"train\"][0]\n",
    "# input_text = sample[\"conversations\"]\n",
    "\n",
    "# # Convert the conversation into a string using the tokenizer's chat template\n",
    "# input_text_str = tokenizer.apply_chat_template(\n",
    "#     input_text,\n",
    "#     tokenize=False,  # set to True if you want token IDs instead\n",
    "#     add_generation_prompt=False,  # or True if you're about to generate a reply\n",
    "# )\n",
    "\n",
    "# inputs = tokenizer(input_text_str, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "# input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "\n",
    "\n",
    "# attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "\n",
    "# outputs = model.generate(\n",
    "#     input_ids=input_ids,\n",
    "#     attention_mask=attention_mask,\n",
    "#     max_new_tokens=256,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.7,\n",
    "#     top_p=0.95,\n",
    "#     top_k=50,\n",
    "# )\n",
    "\n",
    "# output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(\"Output Text:\")\n",
    "# print(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reward_func(\n",
    "    completions: List[Union[str, List[Dict[str, str]], Dict[str, str]]], **kwargs: Any\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    Reward function that checks if completions follow the required format pattern.\n",
    "\n",
    "    The function checks each completion for the pattern <think>...</think><answer>...</answer>\n",
    "    and assigns a binary reward (1.0 for matching, 0.0 for non-matching).\n",
    "\n",
    "    Args:\n",
    "        completions: List of model completions. Can be one of:\n",
    "            - List of strings\n",
    "            - List of lists containing dictionaries with \"content\" key\n",
    "            - List of dictionaries with \"content\" key\n",
    "        **kwargs: Additional keyword arguments (unused but allowed for compatibility)\n",
    "\n",
    "    Returns:\n",
    "        List[float]: A list of reward scores (1.0 for matching format, 0.0 otherwise)\n",
    "\n",
    "    Example:\n",
    "        >>> completions = [\"<think>Some reasoning</think><answer>42</answer>\"]\n",
    "        >>> efficient_format_reward(completions)\n",
    "        [1.0]\n",
    "\n",
    "        >>> completions = [[{\"content\": \"<think>Reasoning</think><answer>Result</answer>\"}]]\n",
    "        >>> efficient_format_reward(completions)\n",
    "        [1.0]\n",
    "    \"\"\"\n",
    "    pattern = r\"<think>.*?</think>\\s*<answer>.*?</answer>\"\n",
    "    rewards = []\n",
    "\n",
    "    for completion in completions:\n",
    "        try:\n",
    "            # Handle different input formats\n",
    "            if isinstance(completion, list):\n",
    "                content = completion[0][\"content\"]\n",
    "            elif isinstance(completion, dict):\n",
    "                content = completion[\"content\"]\n",
    "            else:\n",
    "                content = completion\n",
    "\n",
    "            # Check if the pattern is present anywhere in the string using DOTALL to match across lines\n",
    "            match = re.search(pattern, content, re.DOTALL)\n",
    "            rewards.append(1.0 if match else 0.0)\n",
    "        except (KeyError, IndexError, TypeError):\n",
    "            # Handle cases where the expected structure isn't found\n",
    "            rewards.append(0.0)\n",
    "\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equation_reward_func(completions, target, nums, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluates completions based on:\n",
    "    2. Mathematical correctness of the answer\n",
    "\n",
    "    Args:\n",
    "        completions (list[str]): Generated outputs\n",
    "        target (list[str]): Expected answers\n",
    "        nums (list[str]): Available numbers\n",
    "\n",
    "    Returns:\n",
    "        list[float]: Reward scores\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    for completion, gt, numbers in zip(completions, target, nums):\n",
    "        try:\n",
    "            # add synthetic <think> as its already part of the prompt and prefilled for the assistant to more easily match the regex\n",
    "            completion = \"<think>\" + completion\n",
    "\n",
    "            # Check if the format is correct\n",
    "            match = re.search(r\"<answer>(.*?)<\\/answer>\", completion)\n",
    "            if match is None:\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Extract the \"answer\" part from the completion\n",
    "            equation = match.group(1).strip()\n",
    "\n",
    "            # Extract all numbers from the equation\n",
    "            used_numbers = [int(n) for n in re.findall(r\"\\d+\", equation)]\n",
    "\n",
    "            # Check if all numbers are used exactly once\n",
    "            if sorted(used_numbers) != sorted(numbers):\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Define a regex pattern that only allows numbers, operators, parentheses, and whitespace\n",
    "            allowed_pattern = r\"^[\\d+\\-*/().\\s]+$\"\n",
    "            if not re.match(allowed_pattern, equation):\n",
    "                rewards.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Evaluate the equation with restricted globals and locals\n",
    "            result = eval(equation, {\"__builtins__\": None}, {})\n",
    "\n",
    "            # Check if the equation is correct and matches the ground truth\n",
    "            if abs(float(result) - float(gt)) < 1e-5:\n",
    "                rewards.append(1.0)\n",
    "            else:\n",
    "                rewards.append(0.0)\n",
    "        except Exception:\n",
    "\n",
    "            # If evaluation fails, reward is 0\n",
    "            rewards.append(0.0)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_sample_1 = \"\"\"We need to find an equation using the numbers 19, 36, 55, and 7\n",
    "exactly once, with basic arithmetic operations, that equals 65. One possible\n",
    "combination is 55 + 36 - 19 + 7... </think>\n",
    "<answer> 55 + 36 - 7 - 19 </answer>\"\"\"\n",
    "\n",
    "correct_sample_2 = \"\"\" ... </think>\n",
    "<answer> 55 + 36 - 7 - 19 </answer>\"\"\"\n",
    "\n",
    "wrong_format = \"\"\"User: Using the numbers [19, 36, 55, 7], create an equation that equals 65.\"\"\"\n",
    "\n",
    "wrong_format_2 = \"\"\"To find the equation that equals 79 using the numbers 95, 78, 6, 88, I'll start by adding 88 and 95:                      \n",
    "95 + 88 = 183                                                                                                              \n",
    "Now, let's subtract 104 from 183 to get 79:\n",
    "183 - 104 = 79\n",
    "<think> 183 - 104 = 79 </think><think> 183 - 104 = 79 </think><answer> 183 - 104 = 79 </answer>\"\"\"\n",
    "\n",
    "wrong_result = \"\"\" ... </think>\n",
    "<answer> 55 + 36 - 7 - 18 </answer>\"\"\"\n",
    "\n",
    "\n",
    "test_rewards = format_reward_func(\n",
    "    completions=[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result],\n",
    "    target=[\"65\", \"65\", \"65\", \"65\", \"65\"],\n",
    "    nums=[[19, 36, 55, 7]] * 5,\n",
    ")\n",
    "assert test_rewards == [1.0, 1.0, 0.0, 0.0, 1.0], \"Reward function is not working\"\n",
    "test_rewards = equation_reward_func(\n",
    "    completions=[correct_sample_1, correct_sample_2, wrong_format, wrong_format_2, wrong_result],\n",
    "    target=[\"65\", \"65\", \"65\", \"65\", \"65\"],\n",
    "    nums=[[19, 36, 55, 7]] * 5,\n",
    ")\n",
    "assert test_rewards == [1.0, 1.0, 0.0, 0.0, 0.0], \"Reward function is not working\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = GRPOConfig(\n",
    "    output_dir=\"./output\",\n",
    "    learning_rate=1e-5,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=1,\n",
    "    bf16=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=1,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    # GRPO specific parameters\n",
    "    max_prompt_length=64,\n",
    "    max_completion_length=128,  # max length of the generated output for our solution\n",
    "    num_generations=4,\n",
    "    beta=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer\n",
    "# Seems to create a column \"completions\" with the generated outputs\n",
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    reward_funcs=[\n",
    "        format_reward_func,\n",
    "        equation_reward_func,\n",
    "    ],\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt_sample = (\n",
    "    \"Using the numbers 95, 21, 3,, create an equation that equals 88 and provide the solution step by step. \"\n",
    "    \"You can use basic arithmetic operations (+, -, *, /) and parentheses to create the equation. \"\n",
    "    \"Each number can only be used once. If it is not possible to create an equation, please say 'impossible'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_sample_output = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt_sample},\n",
    "]\n",
    "\n",
    "# Convert the conversation into a string using the tokenizer's chat template\n",
    "input_text_sample_str = tokenizer.apply_chat_template(\n",
    "    input_text_sample_output,\n",
    "    tokenize=False,  # set to True if you want token IDs instead\n",
    "    add_generation_prompt=True,  # or True if you're about to generate a reply\n",
    ")\n",
    "\n",
    "inputs_sample = tokenizer(input_text_sample_str, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "input_ids_sample = inputs_sample[\"input_ids\"].to(model.device)\n",
    "attention_mask_sample = inputs_sample[\"attention_mask\"].to(model.device)\n",
    "outputs_sample = model.generate(\n",
    "    input_ids=input_ids_sample,\n",
    "    attention_mask=attention_mask_sample,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    ")\n",
    "output_text_sample = tokenizer.decode(outputs_sample[0], skip_special_tokens=True)\n",
    "print(\"Output Text:\")\n",
    "print(output_text_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
