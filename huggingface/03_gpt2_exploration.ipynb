{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saul/.pyenv/versions/3.11.6/envs/pytorch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze gpt2 moddel and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: Machine Learning with PyTorch can do amazing\n"
     ]
    }
   ],
   "source": [
    "seq = \"Machine Learning with PyTorch can do amazing\"\n",
    "print(\"Input sequence:\", seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input data structure: \n",
      " {'input_ids': tensor([[37573, 18252,   351,  9485, 15884,   354,   460,   466,  4998]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(seq, return_tensors=\"pt\").to(device)\n",
    "print(\"Tokenized input data structure: \\n\", inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token IDs and their words: \n",
      "tensor(37573) Machine\n",
      "tensor(18252)  Learning\n",
      "tensor(351)  with\n",
      "tensor(9485)  Py\n",
      "tensor(15884) Tor\n",
      "tensor(354) ch\n",
      "tensor(460)  can\n",
      "tensor(466)  do\n",
      "tensor(4998)  amazing\n"
     ]
    }
   ],
   "source": [
    "input_ids = inputs[\"input_ids\"]  # just IDS, no attn mask\n",
    "print(\"\\nToken IDs and their words: \")\n",
    "for id in input_ids[0]:\n",
    "  word = tokenizer.decode(id)\n",
    "  print(id, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 50257\n",
      "Logits Shape: torch.Size([1, 50257])\n",
      "Logits: tensor([[-116.6087, -119.3603, -123.8558,  ..., -125.5929, -129.2048,\n",
      "         -119.6724]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "  logits = outputs.logits[:, -1, :] # last token, pulling out all logits\n",
    "\n",
    "print(\"Vocabulary Size:\", logits.shape[-1])\n",
    "print(\"Logits Shape:\", logits.shape)\n",
    "print(\"Logits:\", logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Token: 1243\n",
      "Decoded Word:  things\n",
      "Best Token Probability: tensor(0.8678)\n",
      "Probabilities: tensor([[4.3801e-05, 2.7958e-06, 3.1197e-08,  ..., 5.4916e-09, 1.4827e-10,\n",
      "         2.0463e-06]])\n"
     ]
    }
   ],
   "source": [
    "probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "print(\"Next Token:\", torch.argmax(probs).item())\n",
    "print(\"Decoded Word:\", tokenizer.decode(torch.argmax(probs).item()))\n",
    "\n",
    "print(\"Best Token Probability:\", torch.max(probs))\n",
    "print(\"Probabilities:\", probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Token ID</th>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logits</th>\n",
       "      <td>-106.714706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Probability</th>\n",
       "      <td>0.867764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Word</th>\n",
       "      <td>things</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Value\n",
       "Token ID              1243\n",
       "Logits         -106.714706\n",
       "Probability       0.867764\n",
       "Predicted Word      things"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_id = torch.argmax(logits).item()\n",
    "logit_value = logits[0, pred_id].cpu().item()\n",
    "prob_value = probs[0, pred_id].cpu().item()\n",
    "pred_word = tokenizer.decode(pred_id)\n",
    "pd.DataFrame([pred_id, logit_value, prob_value, pred_word], \n",
    "              index=['Token ID', 'Logits', 'Probability', 'Predicted Word'], columns =['Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at logic for predicting next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Choice 1</th>\n",
       "      <th>Choice 2</th>\n",
       "      <th>Choice 3</th>\n",
       "      <th>Choice 4</th>\n",
       "      <th>Choice 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing</td>\n",
       "      <td>things (86.78%)</td>\n",
       "      <td>work (2.53%)</td>\n",
       "      <td>stuff (2.08%)</td>\n",
       "      <td>thing (0.58%)</td>\n",
       "      <td>tasks (0.41%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>. (27.47%)</td>\n",
       "      <td>with (16.45%)</td>\n",
       "      <td>, (12.07%)</td>\n",
       "      <td>for (8.76%)</td>\n",
       "      <td>in (4.32%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>\\n (22.20%)</td>\n",
       "      <td>It (13.30%)</td>\n",
       "      <td>The (4.67%)</td>\n",
       "      <td>I (4.01%)</td>\n",
       "      <td>We (3.84%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>\\n (99.79%)</td>\n",
       "      <td>The (0.02%)</td>\n",
       "      <td>I (0.01%)</td>\n",
       "      <td>A (0.01%)</td>\n",
       "      <td>In (0.01%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>The (6.22%)</td>\n",
       "      <td>I (4.16%)</td>\n",
       "      <td>This (3.38%)</td>\n",
       "      <td>Py (2.76%)</td>\n",
       "      <td>In (2.50%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>Py (6.27%)</td>\n",
       "      <td>first (4.72%)</td>\n",
       "      <td>goal (2.83%)</td>\n",
       "      <td>Python (2.58%)</td>\n",
       "      <td>main (2.25%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>Tor (96.67%)</td>\n",
       "      <td>Py (0.50%)</td>\n",
       "      <td>T (0.27%)</td>\n",
       "      <td>tor (0.12%)</td>\n",
       "      <td>Data (0.07%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>ch (99.68%)</td>\n",
       "      <td>cher (0.09%)</td>\n",
       "      <td>che (0.09%)</td>\n",
       "      <td>cho (0.02%)</td>\n",
       "      <td>ches (0.01%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>project (3.77%)</td>\n",
       "      <td>library (3.36%)</td>\n",
       "      <td>API (2.66%)</td>\n",
       "      <td>framework (2.17%)</td>\n",
       "      <td>team (1.98%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Machine Learning with PyTorch can do amazing t...</td>\n",
       "      <td>is (32.44%)</td>\n",
       "      <td>has (11.87%)</td>\n",
       "      <td>was (6.17%)</td>\n",
       "      <td>uses (2.95%)</td>\n",
       "      <td>aims (2.53%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input          Choice 1  \\\n",
       "0       Machine Learning with PyTorch can do amazing   things (86.78%)   \n",
       "1  Machine Learning with PyTorch can do amazing t...        . (27.47%)   \n",
       "2  Machine Learning with PyTorch can do amazing t...       \\n (22.20%)   \n",
       "3  Machine Learning with PyTorch can do amazing t...       \\n (99.79%)   \n",
       "4  Machine Learning with PyTorch can do amazing t...       The (6.22%)   \n",
       "5  Machine Learning with PyTorch can do amazing t...        Py (6.27%)   \n",
       "6  Machine Learning with PyTorch can do amazing t...      Tor (96.67%)   \n",
       "7  Machine Learning with PyTorch can do amazing t...       ch (99.68%)   \n",
       "8  Machine Learning with PyTorch can do amazing t...   project (3.77%)   \n",
       "9  Machine Learning with PyTorch can do amazing t...       is (32.44%)   \n",
       "\n",
       "           Choice 2        Choice 3            Choice 4        Choice 5  \n",
       "0      work (2.53%)   stuff (2.08%)       thing (0.58%)   tasks (0.41%)  \n",
       "1     with (16.45%)      , (12.07%)         for (8.76%)      in (4.32%)  \n",
       "2       It (13.30%)     The (4.67%)           I (4.01%)      We (3.84%)  \n",
       "3       The (0.02%)       I (0.01%)           A (0.01%)      In (0.01%)  \n",
       "4         I (4.16%)    This (3.38%)          Py (2.76%)      In (2.50%)  \n",
       "5     first (4.72%)    goal (2.83%)      Python (2.58%)    main (2.25%)  \n",
       "6        Py (0.50%)       T (0.27%)         tor (0.12%)    Data (0.07%)  \n",
       "7      cher (0.09%)     che (0.09%)         cho (0.02%)    ches (0.01%)  \n",
       "8   library (3.36%)     API (2.66%)   framework (2.17%)    team (1.98%)  \n",
       "9      has (11.87%)     was (6.17%)        uses (2.95%)    aims (2.53%)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_txt = \"Transformers are the \"                    # This one is interesting to see how things change\n",
    "#input_txt = \"Transformers are built using the\"         # Note the word pieces\n",
    "\n",
    "input_txt = \"Machine Learning with PyTorch can do amazing\"\n",
    "\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "iterations = []\n",
    "n_steps = 10\n",
    "choices_per_step = 5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(n_steps):\n",
    "        iteration = dict()\n",
    "        iteration[\"Input\"] = tokenizer.decode(input_ids[0])\n",
    "        output = model(input_ids=input_ids)\n",
    "        \n",
    "        # Select logits of the first batch and the last token and apply softmax to get the probability\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        next_token_probs = torch.softmax(next_token_logits, dim=-1)\n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)\n",
    "        \n",
    "        # Store tokens with highest probabilities in our little table\n",
    "        for choice_idx in range(choices_per_step):\n",
    "            token_id = sorted_ids[choice_idx]\n",
    "            token_prob = next_token_probs[token_id].cpu().numpy()\n",
    "            token_choice = (\n",
    "                f\"{tokenizer.decode(token_id)} ({100 * token_prob:.2f}%)\"\n",
    "            )\n",
    "            iteration[f\"Choice {choice_idx+1}\"] = token_choice\n",
    "        iterations.append(iteration)\n",
    "\n",
    "            \n",
    "        # Append predicted next token to input\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[None, 0, None]], dim=-1)\n",
    "\n",
    "pd.DataFrame(iterations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
