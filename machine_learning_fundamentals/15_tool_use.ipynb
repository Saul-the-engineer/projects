{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saul/.pyenv/versions/3.11.8/envs/langchain/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import json\n",
    "import inspect\n",
    "import types\n",
    "import torch\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from langchain.agents import tool\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI knows  how to recognize when to use tool functions and structure the input for them. However the OpenAI API takes JSON as input and we should convert our functions to JSON.\n",
    "\n",
    "Converting a Python function to JSON directly isn't straightforward because JSON is a data interchange format, and functions in Python are executable code. However, you can represent certain aspects of a function in JSON, such as its name, arguments, and possibly its source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_two_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"This function will add a and b together and return the result.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "def multiply_two_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"This function will multiply a by b and return the result.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide_two_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"This function will divide a by b and return the result.\"\"\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual JSON Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'add_two_numbers',\n",
       "  'description': 'add_two_numbers(a: float, b: float) -> float - This function will add a and b together and return the result.',\n",
       "  'parameters': {'title': 'add_two_numbersSchemaSchema',\n",
       "   'type': 'object',\n",
       "   'properties': {'a': {'title': 'A', 'type': 'number'},\n",
       "    'b': {'title': 'B', 'type': 'number'}},\n",
       "   'required': ['a', 'b']}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_two_numbers_json = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'add_two_numbers',\n",
    "        'description': 'add_two_numbers(a: float, b: float) -> float - This function will add a and b together and return the result.',\n",
    "        'parameters': {\n",
    "            'title': 'add_two_numbersSchemaSchema',\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'a': {'title': 'A', 'type': 'number'},\n",
    "                'b': {'title': 'B', 'type': 'number'}\n",
    "                },\n",
    "            'required': ['a', 'b']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "add_two_numbers_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to JSON with langchain\n",
    "\n",
    "Langchain generally does pretty well but messes up on the default arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'add_two_numbers',\n",
       "  'description': 'add_two_numbers(a: float, b: float) -> float - This function will add a and b together and return the result.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "   'required': ['a', 'b']}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_calling_def = convert_to_openai_tool(tool(add_two_numbers))\n",
    "function_calling_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to JSON with Pydantic\n",
    "\n",
    "Pydantic will give more control over the conversion process. \n",
    "\n",
    "However, it requires more manual work. Notice that Pydantic is missing the description of the function. We can add it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'properties': {'a': {'title': 'A', 'type': 'number'},\n",
       "  'b': {'title': 'B', 'type': 'number'}},\n",
       " 'required': ['a', 'b'],\n",
       " 'title': 'AddTwoNumbers',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AddTwoNumbers(BaseModel):\n",
    "    a: float\n",
    "    b: float\n",
    "\n",
    "AddTwoNumbers.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "client = OpenAI(api_key = os.environ.get(\"OPENAI_API_KEY\"))\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that can perform math operations. Please help me with the following math problem.\",\n",
    "        },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Please add 1 and 5\",\n",
    "        },\n",
    "    ]\n",
    "function = convert_to_openai_tool(tool(add_two_numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-16k-0613\", \n",
    "    messages=messages, \n",
    "    tools=[function],\n",
    "    max_tokens=100,\n",
    "    temperature=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out the result,\n",
    "\n",
    "Notice that result.choices.[0].message.content is None.\n",
    "\n",
    "We see that the reason the call ended was due to 'tool_calls', we can figure out which tool to call and finish the call and the arguments to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChatCompletion(\\n    id=\\'chatcmpl-9FpiN2BywNG8jHVgaRTkEfMRgugGW\\', \\n    choices=[\\n        Choice(\\n            finish_reason=\\'tool_calls\\', \\n            index=0, \\n            logprobs=None, \\n            message=ChatCompletionMessage(\\n                content=None, \\n                role=\\'assistant\\', \\n                function_call=None, \\n                tool_calls=[\\n                    ChatCompletionMessageToolCall(\\n                        id=\\'call_rUH4nMcpv9syrXz0SBJnk0oW\\', \\n                        function=Function(\\n                            arguments=\\'{\\n  \"a\": 1,\\n  \"b\": 5\\n}\\', \\n                            name=\\'add_two_numbers\\',\\n                            ), \\n                        type=\\'function\\',\\n                        )\\n                    ]\\n                )\\n            )\\n        ], \\n    created=1713560739, \\n    model=\\'gpt-3.5-turbo-16k-0613\\', \\n    object=\\'chat.completion\\', \\n    system_fingerprint=None, \\n    usage=CompletionUsage(\\n        completion_tokens=23, \\n        prompt_tokens=98, \\n        total_tokens=121,\\n        )\\n    )\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response\n",
    "\n",
    "\"\"\"\n",
    "ChatCompletion(\n",
    "    id='chatcmpl-9FpiN2BywNG8jHVgaRTkEfMRgugGW', \n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason='tool_calls', \n",
    "            index=0, \n",
    "            logprobs=None, \n",
    "            message=ChatCompletionMessage(\n",
    "                content=None, \n",
    "                role='assistant', \n",
    "                function_call=None, \n",
    "                tool_calls=[\n",
    "                    ChatCompletionMessageToolCall(\n",
    "                        id='call_rUH4nMcpv9syrXz0SBJnk0oW', \n",
    "                        function=Function(\n",
    "                            arguments='{\\n  \"a\": 1,\\n  \"b\": 5\\n}', \n",
    "                            name='add_two_numbers',\n",
    "                            ), \n",
    "                        type='function',\n",
    "                        )\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        ], \n",
    "    created=1713560739, \n",
    "    model='gpt-3.5-turbo-16k-0613', \n",
    "    object='chat.completion', \n",
    "    system_fingerprint=None, \n",
    "    usage=CompletionUsage(\n",
    "        completion_tokens=23, \n",
    "        prompt_tokens=98, \n",
    "        total_tokens=121,\n",
    "        )\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'add_two_numbers'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.tool_calls[0].function.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Well how do I pull the information from the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_process_function_calling(gpt_response: ChatCompletion):\n",
    "    # Check to see if the call terminated on a function call.\n",
    "    finish_reason = gpt_response.choices[0].finish_reason\n",
    "    # We check if we finished for an explicit function call or if we finished because of a long query\n",
    "    # and gpt suggests a function call\n",
    "    if finish_reason == \"tool_calls\":\n",
    "        function_name = gpt_response.choices[0].message.tool_calls[0].function.name\n",
    "        arguments = json.loads(gpt_response.choices[0].message.tool_calls[0].function.arguments)\n",
    "        func = globals()[function_name]\n",
    "        return func(**arguments)\n",
    "    else:\n",
    "        # if not just pass the response through.\n",
    "        return gpt_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = gpt_process_function_calling(response)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do I call all functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [\"add_two_numbers\", \"multiply_two_numbers\", \"divide_two_numbers\"]\n",
    "functions = [convert_to_openai_tool(tool(globals()[t])) for t in funcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'add_two_numbers',\n",
       "   'description': 'add_two_numbers(a: float, b: float) -> float - This function will add a and b together and return the result.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'multiply_two_numbers',\n",
       "   'description': 'multiply_two_numbers(a: float, b: float) -> float - This function will multiply a by b and return the result.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'divide_two_numbers',\n",
       "   'description': 'divide_two_numbers(a: float, b: float) -> float - This function will divide a by b and return the result.',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'a': {'type': 'number'}, 'b': {'type': 'number'}},\n",
       "    'required': ['a', 'b']}}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = [\n",
    "\t\"add 1 and 5\",\n",
    "\t\"multiply 5 by the number: \",\n",
    "\t\"divide the following number up by 15: \"\n",
    "\t\"Repeat the word 'duck' this many times please: \"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notes for the future.\n",
    "\n",
    "ChatGPT seems to have trouble with the mutiplication line. It seems to just be copying the arguments from the previous line; a = 1, b = 5 instead of a = 6, b = 5.\n",
    "\n",
    "Another thing is that it's not repeating the word duck. This is most likely due to the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': ''}, {'role': 'user', 'content': 'add 1 and 5'}]\n",
      "ChatCompletion(id='chatcmpl-9Fr4OQzCbXgX2nJfzKguUlKibUNaK', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_p9xV6U0Yse1C2L06DymISY4x', function=Function(arguments='{\\n  \"a\": 1,\\n  \"b\": 5\\n}', name='add_two_numbers'), type='function')]))], created=1713565948, model='gpt-3.5-turbo-16k-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=171, total_tokens=194))\n",
      "6\n",
      "[{'role': 'system', 'content': ''}, {'role': 'user', 'content': 'multiply 5 by the number: ChatCompletion(id=\\'chatcmpl-9Fr4OQzCbXgX2nJfzKguUlKibUNaK\\', choices=[Choice(finish_reason=\\'tool_calls\\', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role=\\'assistant\\', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\\'call_p9xV6U0Yse1C2L06DymISY4x\\', function=Function(arguments=\\'{\\\\n  \"a\": 1,\\\\n  \"b\": 5\\\\n}\\', name=\\'add_two_numbers\\'), type=\\'function\\')]))], created=1713565948, model=\\'gpt-3.5-turbo-16k-0613\\', object=\\'chat.completion\\', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=171, total_tokens=194))'}]\n",
      "ChatCompletion(id='chatcmpl-9Fr4PO7bJbwsDHnvpPLpY0THuZdnX', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4LRsfGWADk6LDVhp40iZrX7s', function=Function(arguments='{\\n  \"a\": 5,\\n  \"b\": 1\\n}', name='multiply_two_numbers'), type='function')]))], created=1713565949, model='gpt-3.5-turbo-16k-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=361, total_tokens=384))\n",
      "5\n",
      "[{'role': 'system', 'content': ''}, {'role': 'user', 'content': 'divide the following number up by 15: Repeat the word \\'duck\\' this many times please: ChatCompletion(id=\\'chatcmpl-9Fr4PO7bJbwsDHnvpPLpY0THuZdnX\\', choices=[Choice(finish_reason=\\'tool_calls\\', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role=\\'assistant\\', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id=\\'call_4LRsfGWADk6LDVhp40iZrX7s\\', function=Function(arguments=\\'{\\\\n  \"a\": 5,\\\\n  \"b\": 1\\\\n}\\', name=\\'multiply_two_numbers\\'), type=\\'function\\')]))], created=1713565949, model=\\'gpt-3.5-turbo-16k-0613\\', object=\\'chat.completion\\', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=361, total_tokens=384))'}]\n",
      "ChatCompletion(id='chatcmpl-9Fr4QOVkL6RKH8ESWXTuGFEVQDMNV', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FeRgffKcDTfrmfTnXjxAxH8F', function=Function(arguments='{\\n  \"a\": 15,\\n  \"b\": 5\\n}', name='divide_two_numbers'), type='function')]))], created=1713565950, model='gpt-3.5-turbo-16k-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=370, total_tokens=393))\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "raw_output = \"\"\n",
    "for instruction in workflow:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\",\n",
    "            },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruction + f\"{raw_output}\",\n",
    "            }\n",
    "        ]\n",
    "    print(messages)\n",
    "    raw_output = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k-0613\", \n",
    "        messages=messages, \n",
    "        tools=functions,\n",
    "        max_tokens=100,\n",
    "        temperature=0.0,\n",
    "        )\n",
    "    print(raw_output)\n",
    "    output = gpt_process_function_calling(raw_output)\n",
    "    print(output)\n",
    "\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 5, 3.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['add_two_numbers'], ['multiply_two_numbers'], ['divide_two_numbers']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the closest two tools for each step in the workflow\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# List of all functions\n",
    "function_registry = [\"add_two_numbers\", \"multiply_two_numbers\", \"divide_two_numbers\"]\n",
    "\n",
    "# Use the inspect library to get a string version of the function\n",
    "# including the docstring\n",
    "function_descriptions = [inspect.getsource(globals()[func]) for func in function_registry]\n",
    "\n",
    "# Embed every function\n",
    "function_embeddings = embedder.encode(function_descriptions, convert_to_tensor=True)\n",
    "\n",
    "top_k = min(1, len(function_descriptions))\n",
    "workflow_functions = []\n",
    "\n",
    "# step through each workflow instruction and encode it.\n",
    "for query in workflow:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, function_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\t# We only add a function if it's closer than .25 by cosine distance.\n",
    "    if max(cos_scores) > .2:\n",
    "        workflow_functions.append([function_registry[i] for i in top_results.indices.tolist()])\n",
    "    else:\n",
    "        workflow_functions.append([])\n",
    "workflow_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.3775], device='cuda:0'),\n",
       "indices=tensor([2], device='cuda:0'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': ''}, {'role': 'user', 'content': 'add 1 and 5 '}]\n",
      "[{'role': 'system', 'content': ''}, {'role': 'user', 'content': 'multiply 5 by the number:  6'}]\n",
      "[{'role': 'system', 'content': ''}, {'role': 'user', 'content': \"divide the following number up by 15: Repeat the word 'duck' this many times please:  30\"}]\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "output = \"\"\n",
    "for instruction, functions in zip(workflow, workflow_functions):\n",
    "    kwargs = {}\n",
    "    if len(functions) > 0:\n",
    "        functions = [convert_to_openai_tool(tool(globals()[t])) for t in functions]\n",
    "        kwargs = {\"tools\": functions}\n",
    "    messages = [{\"role\": \"system\", \"content\": \"\"},\n",
    "                {\"role\": \"user\", \"content\": instruction + f\" {output}\"}]\n",
    "    print(messages)\n",
    "    output = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-16k-0613\", \n",
    "        messages=messages,\n",
    "        **kwargs,\n",
    "        max_tokens=100,\n",
    "        temperature=0.0,\n",
    "        )\n",
    "    output = gpt_process_function_calling(output)\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 30, 2.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just messing around for chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": \"\"},\n",
    "            {\"role\": \"user\", \"content\": \"repeat the word duck 20 times\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-16k-0613\", \n",
    "    messages=messages,\n",
    "    max_tokens=100,\n",
    "    temperature=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"assistant\", \"content\": output.choices[0].message.content})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Now tell me why did the chicken cross the road?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': ''},\n",
       " {'role': 'user', 'content': 'repeat the word duck 20 times'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck duck'},\n",
       " {'role': 'user',\n",
       "  'content': 'Now tell me why did the chicken cross the road?'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-16k-0613\", \n",
    "    messages=messages,\n",
    "    max_tokens=100,\n",
    "    temperature=0.0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The classic answer to why the chicken crossed the road is to get to the other side. However, this answer is often used as a humorous or ironic response to a seemingly simple question. It\\'s a play on words, as \"the other side\" can refer to the other side of the road, but it can also be interpreted as crossing over to the afterlife. Ultimately, the question is meant to be a lighthearted joke rather than a serious inquiry.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
