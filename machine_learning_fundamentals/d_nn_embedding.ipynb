{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WTF does nn.Embedding do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming train_dataset[0][0] is a 1-D tensor\n",
    "train_data = torch.rand(10,1)\n",
    "\n",
    "# Assuming num_embeddings is 25, as you've used in nn.Embedding(1, 25)\n",
    "num_embeddings = 25\n",
    "\n",
    "# Ensure input indices are within the range of num_embeddings\n",
    "train_data_clamped = torch.clamp(train_data, 0, num_embeddings - 1).long()\n",
    "\n",
    "# Now, create the embedding layer\n",
    "linear = nn.Embedding(num_embeddings, 25)\n",
    "\n",
    "# Pass the input indices through the embedding layer\n",
    "output = linear(train_data_clamped)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
