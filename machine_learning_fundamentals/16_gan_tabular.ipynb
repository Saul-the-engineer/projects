{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs) for Tabular Data Generation with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb85c227410>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0) # Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Syntethic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points\n",
    "n = 1000\n",
    "\n",
    "# generate random data for the first column\n",
    "first_column = torch.rand(n, 1).to(device)\n",
    "\n",
    "# Create second and third columns based on the relationships\n",
    "second_column = 2 * first_column\n",
    "third_column = 2 * second_column\n",
    "\n",
    "# Combine the columns\n",
    "data = torch.cat((first_column, second_column, third_column), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models and move them to the device\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# Loss and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1000/5000], d_loss: 1.3752, g_loss: 0.6964\n",
      "Epoch [2000/5000], d_loss: 1.3858, g_loss: 0.6953\n",
      "Epoch [3000/5000], d_loss: 1.3306, g_loss: 0.7926\n",
      "Epoch [4000/5000], d_loss: 1.3851, g_loss: 0.6995\n",
      "Epoch [5000/5000], d_loss: 1.3839, g_loss: 0.6937\n"
     ]
    }
   ],
   "source": [
    "# Training the GAN\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Train discriminator\n",
    "    optimizer_d.zero_grad()\n",
    "\n",
    "    real_data = data\n",
    "    real_labels = torch.ones(n, 1).to(device)\n",
    "    outputs = discriminator(real_data)\n",
    "    d_loss_real = criterion(outputs, real_labels)\n",
    "\n",
    "    # Generate fake data\n",
    "    noise = torch.randn(n, 3).to(device)\n",
    "    fake_data = generator(noise)\n",
    "    fake_labels = torch.zeros(n, 1).to(device)\n",
    "    outputs = discriminator(fake_data.detach())\n",
    "    d_loss_fake = criterion(outputs, fake_labels)\n",
    "\n",
    "    # Backprop and optimize\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    d_loss.backward()\n",
    "    optimizer_d.step()\n",
    "\n",
    "    # Train generator\n",
    "    optimizer_g.zero_grad()\n",
    "    outputs = discriminator(fake_data)\n",
    "    g_loss = criterion(outputs, real_labels)\n",
    "    g_loss.backward()\n",
    "    optimizer_g.step()\n",
    "\n",
    "    # Print losses\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Data (First 10 rows):\n",
      "[0.85301065 1.6151371  3.277037  ]\n",
      "[0.28591636 0.5468786  1.1151662 ]\n",
      "[0.19395384 0.36494565 0.7560951 ]\n",
      "[0.5969087 1.133051  2.3002656]\n",
      "[0.71670544 1.360366   2.765015  ]\n",
      "[0.8928284 1.670333  3.3818266]\n",
      "[0.4100025 0.7811587 1.5839252]\n",
      "[0.17398658 0.32405397 0.676839  ]\n",
      "[0.06351195 0.11708003 0.25542825]\n",
      "[0.43641403 0.82894945 1.7054884 ]\n",
      "\n",
      "Validation (For the first 10 rows):\n",
      "First: 0.8530, Expected Second: 1.7060, Actual Second: 1.6151\n",
      "Second: 1.6151, Expected Third: 3.2303, Actual Third: 3.2770\n",
      "\n",
      "First: 0.2859, Expected Second: 0.5718, Actual Second: 0.5469\n",
      "Second: 0.5469, Expected Third: 1.0938, Actual Third: 1.1152\n",
      "\n",
      "First: 0.1940, Expected Second: 0.3879, Actual Second: 0.3649\n",
      "Second: 0.3649, Expected Third: 0.7299, Actual Third: 0.7561\n",
      "\n",
      "First: 0.5969, Expected Second: 1.1938, Actual Second: 1.1331\n",
      "Second: 1.1331, Expected Third: 2.2661, Actual Third: 2.3003\n",
      "\n",
      "First: 0.7167, Expected Second: 1.4334, Actual Second: 1.3604\n",
      "Second: 1.3604, Expected Third: 2.7207, Actual Third: 2.7650\n",
      "\n",
      "First: 0.8928, Expected Second: 1.7857, Actual Second: 1.6703\n",
      "Second: 1.6703, Expected Third: 3.3407, Actual Third: 3.3818\n",
      "\n",
      "First: 0.4100, Expected Second: 0.8200, Actual Second: 0.7812\n",
      "Second: 0.7812, Expected Third: 1.5623, Actual Third: 1.5839\n",
      "\n",
      "First: 0.1740, Expected Second: 0.3480, Actual Second: 0.3241\n",
      "Second: 0.3241, Expected Third: 0.6481, Actual Third: 0.6768\n",
      "\n",
      "First: 0.0635, Expected Second: 0.1270, Actual Second: 0.1171\n",
      "Second: 0.1171, Expected Third: 0.2342, Actual Third: 0.2554\n",
      "\n",
      "First: 0.4364, Expected Second: 0.8728, Actual Second: 0.8289\n",
      "Second: 0.8289, Expected Third: 1.6579, Actual Third: 1.7055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# After training, generate some synthetic data\n",
    "with torch.no_grad():\n",
    "    test_noise = torch.randn(n, 3).to(device)\n",
    "    generated_data = generator(test_noise).cpu().numpy()\n",
    "\n",
    "# Print the first 10 rows of generated data\n",
    "print(\"Generated Data (First 10 rows):\")\n",
    "for i in range(10):\n",
    "    print(generated_data[i])\n",
    "\n",
    "# To validate if relationships hold:\n",
    "print(\"\\nValidation (For the first 10 rows):\")\n",
    "for i in range(10):\n",
    "    print(f\"First: {generated_data[i][0]:.4f}, Expected Second: {2*generated_data[i][0]:.4f}, Actual Second: {generated_data[i][1]:.4f}\")\n",
    "    print(f\"Second: {generated_data[i][1]:.4f}, Expected Third: {2*generated_data[i][1]:.4f}, Actual Third: {generated_data[i][2]:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
