{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets For Reinforcement Learning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and exploring the datasets\n",
    "\n",
    "\"Reinforcement Learning from Human Feedback\" **(RLHF)** requires the following datasets:\n",
    "- Preference dataset\n",
    "  - Input prompt, candidate response 0, candidate response 1, choice (candidate 0 or 1)\n",
    "- Prompt dataset\n",
    "  - Input prompt only, no response\n",
    "\n",
    "This is the dataset that is used as the preferential dataset. It's recommended to have somewhere between 5,000 and 10,000 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_dataset_path = 'sample_preference.jsonl'\n",
    "\n",
    "preference_data = []\n",
    "\n",
    "with open(preference_dataset_path) as f:\n",
    "    for line in f:\n",
    "        preference_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download preference data as jsonl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print out to explore the preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = preference_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(sample_1)) #dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary has four keys\n",
    "print(sample_1.keys()) #dict_keys(['input_text', 'candidate_0', 'candidate_1', 'choice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Key: 'input_test' is a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1['input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with another examples from the list, and discover that all data end the same way\n",
    "preference_data[2]['input_text'][-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print 'candidate_0' and 'candidate_1', these are the completions for the same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"candidate_0:\\n{sample_1.get('candidate_0')}\\n\")\n",
    "print(f\"candidate_1:\\n{sample_1.get('candidate_1')}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print 'choice', this is the human labeler's preference for the results completions (candidate_0 and candidate_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"choice: {sample_1.get('choice')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_dataset_path = 'sample_prompt.jsonl'\n",
    "prompt_data = []\n",
    "with open(prompt_dataset_path) as f:\n",
    "    for line in f:\n",
    "        prompt_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many prompts there are in this dataset\n",
    "len(prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: It is important that the prompts in both datasets, the preference and the prompt, come from the same distribution. \n",
    "\n",
    "For this lesson, all the prompts come from the same dataset of [Reddit posts](https://github.com/openai/summarize-from-feedback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print the information in the prompt dataset with a better visualization\n",
    "def print_d(d):\n",
    "    for key, val in d.items():        \n",
    "        print(f\"key:{key}\\nval:{val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_d(prompt_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with another prompt from the list \n",
    "print_d(prompt_data[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
