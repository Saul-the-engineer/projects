{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "Matrix factorization is a class of collaborative filtering algorithms used in recommendation systems. The goal of matrix factorization is to learn the latent preferences of users and the latent attributes of items from known ratings (learn the latent factors of users and items). Matrix factorization can be done by various techniques including Singular Value Decomposition (SVD) and Alternating Least Squares (ALS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user-item interactions (user_id, item_id, rating)\n",
    "# In this example, we have 3 users and 5 items\n",
    "# Entry 1: User 0 rates Item 0 with 5\n",
    "# Entry 2: User 0 rates Item 1 with 3\n",
    "# Entry 3: User 0 rates Item 2 with 1\n",
    "interactions = [\n",
    "    (0, 0, 5),\n",
    "    (0, 1, 3),\n",
    "    (0, 2, 1),\n",
    "    (1, 0, 4),\n",
    "    (1, 3, 2),\n",
    "    (2, 1, 5),\n",
    "    (2, 2, 4),\n",
    "    (2, 4, 2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "user_tensor = torch.LongTensor([x[0] for x in interactions])\n",
    "item_tensor = torch.LongTensor([x[1] for x in interactions])\n",
    "rating_tensor = torch.FloatTensor([x[2] for x in interactions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1, 2, 2, 2])\n",
      "tensor([0, 1, 2, 0, 3, 1, 2, 4])\n",
      "tensor([5., 3., 1., 4., 2., 5., 4., 2.])\n"
     ]
    }
   ],
   "source": [
    "print(user_tensor)\n",
    "print(item_tensor)\n",
    "print(rating_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building of Matrix Factorization\n",
    "\n",
    "Matrix factorization is a collaborative filtering technique that creates a recommendation model by learning compact representations (called embedding vectors) for each user and each item. These embedding vectors capture latent features, or hidden characteristics, that summarize patterns in user preferences and item attributes without needing explicit labels like \"action\" or \"romance.\"\n",
    "\n",
    "Each embedding vector represents a user or item in a lower-dimensional space, where each dimension relates to an underlying feature or preference. For instance, a user vector may capture a preference for \"action movies\" as a positive value on one dimension, while an item vector might have a similarly high score in that dimension if it’s an action movie.\n",
    "\n",
    "To predict a rating, the model calculates the dot product of the user and item embedding vectors. This dot product measures the compatibility between a user and an item in the latent space. A high dot product indicates a strong match, while a low dot product suggests a weaker match.\n",
    "\n",
    "During training, the model learns optimal embeddings by minimizing the mean squared error (MSE) between the predicted and actual ratings in the dataset. This optimization allows the model to adjust the embedding vectors to better represent user preferences and item characteristics, improving recommendation accuracy. Once trained, the model can predict ratings for new user-item pairs based on these learned embeddings, effectively generalizing user preferences to items they haven’t interacted with directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the matrix factorization model\n",
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_factors):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        # Embedding for users and items\n",
    "        # Shape: (num_users, num_factors)\n",
    "        self.user_factors = nn.Embedding(num_users, num_factors)  # User latent factors\n",
    "        # Shape: (num_items, num_factors)\n",
    "        self.item_factors = nn.Embedding(num_items, num_factors)  # Item latent factors\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        # Dot product of user and item latent factors to get the predicted rating\n",
    "        # Shape: (batch_size, num_factors)\n",
    "        user_embedding = self.user_factors(user)\n",
    "        # Shape: (batch_size, num_factors)\n",
    "        item_embedding = self.item_factors(item)\n",
    "        # Shape: (batch_size, num_factors) * (batch_size, num_factors) = (batch_size, 1)\n",
    "        return (user_embedding * item_embedding).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_users = 10  # Number of users\n",
    "num_items = 15  # Number of items\n",
    "num_factors = 5  # Number of latent factors\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = MatrixFactorization(num_users, num_items, num_factors)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 16.1182\n",
      "Epoch [20/100], Loss: 12.4053\n",
      "Epoch [30/100], Loss: 9.6322\n",
      "Epoch [40/100], Loss: 7.3787\n",
      "Epoch [50/100], Loss: 5.4465\n",
      "Epoch [60/100], Loss: 3.8017\n",
      "Epoch [70/100], Loss: 2.4587\n",
      "Epoch [80/100], Loss: 1.4391\n",
      "Epoch [90/100], Loss: 0.7383\n",
      "Epoch [100/100], Loss: 0.3167\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: compute predicted ratings\n",
    "    predictions = model(user_tensor, item_tensor)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(predictions, rating_tensor)\n",
    "\n",
    "    # Backward pass and optimization step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print loss for every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User factors:\n",
      "tensor([[-0.1966,  2.0901,  1.4320, -0.6804, -1.1663],\n",
      "        [-0.7826,  1.8078, -0.4175, -0.4707, -0.8836],\n",
      "        [-1.1315,  1.1421, -1.7936,  0.8216, -2.4299],\n",
      "        [ 1.0879, -0.9965,  0.2485,  1.6590,  2.0396],\n",
      "        [-0.4346,  0.1771, -0.9049,  0.2244,  0.8065],\n",
      "        [-1.0381,  0.0959,  0.6811,  0.2722,  1.2688],\n",
      "        [-0.6166, -0.4284, -0.8788, -0.4176,  0.7336],\n",
      "        [-1.2199, -0.7998,  1.1784, -0.9541,  0.5998],\n",
      "        [-0.0500,  0.1147,  0.0867,  0.4897,  0.4198],\n",
      "        [-0.6322, -2.2283, -0.7515, -1.5604, -1.0636]])\n",
      "Item factors:\n",
      "tensor([[-0.9029,  1.2594,  1.1301,  0.1076, -0.4183],\n",
      "        [ 0.8131,  0.5687, -0.6819, -0.4225, -1.6167],\n",
      "        [-2.2512,  1.1665,  0.0447,  2.0653,  0.6119],\n",
      "        [-0.0946,  1.1192, -0.7338,  0.5828,  0.0843],\n",
      "        [-1.1505,  0.5486,  0.8121, -0.3932, -0.6636],\n",
      "        [-0.7133,  0.6834, -0.8782,  0.5055,  0.8170],\n",
      "        [ 2.4815, -1.3402, -0.3372, -0.8092, -0.2974],\n",
      "        [ 0.8044, -0.7979, -0.2265, -0.3909,  0.1487],\n",
      "        [ 1.0091, -2.0912,  0.0268,  0.2264, -0.6713],\n",
      "        [ 1.7833,  0.8612,  0.1457,  0.7873,  1.3738],\n",
      "        [ 1.0900, -0.9126,  1.8085,  0.4948, -0.1084],\n",
      "        [ 0.6039, -0.4380, -1.5022,  1.6584, -1.1259],\n",
      "        [-0.1036, -0.1557, -0.6689, -0.3401,  0.4915],\n",
      "        [ 0.1473,  1.0397,  1.5898, -0.5471,  1.7639],\n",
      "        [ 1.3959,  0.8532, -1.8860, -2.1416,  0.6565]])\n"
     ]
    }
   ],
   "source": [
    "# Print the user and item latent factors\n",
    "user_factors = model.user_factors.weight.data\n",
    "item_factors = model.item_factors.weight.data\n",
    "\n",
    "print(\"User factors:\")\n",
    "print(user_factors)\n",
    "\n",
    "print(\"Item factors:\")\n",
    "print(item_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 0 on item 3: 0.8122\n"
     ]
    }
   ],
   "source": [
    "# Example of making predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    user_id = 0  # Example user\n",
    "    item_id = 3  # Example item\n",
    "    predicted_rating = model(torch.LongTensor([user_id]), torch.LongTensor([item_id]))\n",
    "    print(\n",
    "        f\"Predicted rating for user {user_id} on item {item_id}: {predicted_rating.item():.4f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
